{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f899ef-59f1-4673-ab33-4e6f56cbe16e",
   "metadata": {},
   "source": [
    "# Decoder - 2 layers GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3190e4b-146f-4768-8b51-3bd6f061b081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  32768\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "epochs = 300\n",
    "batch = 32768 # 2^15\n",
    "dataset_folder = '/home/jovyan/share/Raiso/datasets'\n",
    "\n",
    "# tapsize\n",
    "ts = 10 \n",
    "# feature\n",
    "feat_file = os.path.join(dataset_folder, 'B3D71_LFDAS_ALL.pickle') \n",
    "# target\n",
    "tft_flie = os.path.join(dataset_folder, 'B3D71_DLC_HANDXY.npy') \n",
    "\n",
    "print('Batch ', batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e577e39c-65cd-4ac1-95b8-02dfbf015b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5665be76-430f-482d-82d4-5fba4acb9ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184000 38 2\n"
     ]
    }
   ],
   "source": [
    "feat = pickle.load(open(feat_file, 'rb'))\n",
    "tgt = np.load(tft_flie)\n",
    "\n",
    "tdim = feat.shape[0]\n",
    "idim, odim = feat.shape[1], tgt.shape[1]\n",
    "print(tdim, idim, odim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f563b1-72dc-4263-bd91-5601a1465a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dateset(torch.utils.data.Dataset):\n",
    "    def __init__(self, feat, tgt, ts):\n",
    "        print(feat.shape, tgt.shape)\n",
    "        self.feat = torch.Tensor(feat)\n",
    "        self.tgt = torch.Tensor(tgt)\n",
    "        self.tdim = tgt.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.feat[i: i+ts], self.tgt[i+ts-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tdim-ts+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26e3ad7e-3359-4f28-8fc2-3bab1b183fae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128799, 38) (128799, 2)\n",
      "(18401, 38) (18401, 2)\n",
      "(36800, 38) (36800, 2)\n",
      "Shape:  128790 18392 36791\n"
     ]
    }
   ],
   "source": [
    "cut1 = int(0.7 * tdim)\n",
    "cut2 = int(0.8 * tdim)\n",
    "\n",
    "tr_set = Dateset(feat[:cut1], tgt[:cut1], ts)\n",
    "dv_set = Dateset(feat[cut1:cut2], tgt[cut1:cut2], ts)\n",
    "tt_set = Dateset(feat[cut2:], tgt[cut2:], ts)\n",
    "\n",
    "del cut1, cut2\n",
    "print('Shape: ', len(tr_set), len(dv_set), len(tt_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d06ac5-da29-496d-ad85-be46bdc97400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_load = DataLoader(tr_set, batch, shuffle=True,\n",
    "                    drop_last=False, pin_memory=True)  \n",
    "dv_load = DataLoader(dv_set, batch, shuffle=False,\n",
    "                    drop_last=False, pin_memory=True)  \n",
    "tt_load = DataLoader(tt_set, batch, shuffle=False,\n",
    "                    drop_last=False, pin_memory=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783a0a07-1fdf-476f-993e-ba45930c5c21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, idim, odim, ts):\n",
    "        super().__init__()\n",
    "        self.gru1 = nn.GRU(idim, idim, num_layers=1, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        self.gru2 = nn.GRU(2 * idim, 256, num_layers=1, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        self.readout = nn.Sequential(\n",
    "            nn.Linear(256 * 2 * ts, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, odim),  \n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bz, _, _ = x.size()\n",
    "        x, _ = self.gru1(x)\n",
    "        x = nn.functional.layer_norm(x, x.size()[-1:])\n",
    "        x, _ = self.gru2(x)\n",
    "        emb = nn.functional.layer_norm(x, x.size()[-1:]) \n",
    "        yh = self.readout(emb.reshape(bz, -1))\n",
    "        return yh\n",
    "   \n",
    "    def cal_loss(self, yh, y):\n",
    "        return self.criterion(yh, y)\n",
    "\n",
    "model = Decoder(idim, odim, ts).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a54b3-3209-4ea3-b3d2-36dc888044df",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d6f2b-2459-4720-90cb-405874f93753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "tr_loss = []\n",
    "dv_loss = []\n",
    "mini_dv_loss = 2e9\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    for x, y in tr_load:\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yh = model(x) \n",
    "        loss = model.cal_loss(yh, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss.append(loss.detach().cpu().item())\n",
    "\n",
    "    model.eval() \n",
    "    ave_dv_loss = 0\n",
    "    for x, y in dv_load:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            yh = model(x) \n",
    "            loss = model.cal_loss(yh, y)\n",
    "        ave_dv_loss += loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    ave_dv_loss = ave_dv_loss / len(dv_load.dataset)\n",
    "    dv_loss.append(ave_dv_loss)\n",
    "    \n",
    "    if ave_dv_loss < mini_dv_loss:\n",
    "        mini_dv_loss = ave_dv_loss\n",
    "        # print('Saving model (epoch = {:4d}, loss = {:.4f})'.format(e + 1, ave_dv_loss))\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "print(f'time cost: {time.time() - begin}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b543dd-4815-49a0-81b8-f04192da1cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(tr_loss)\n",
    "plt.show()\n",
    "plt.plot(dv_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3b0b6-f8ca-4aa8-946a-0fb180068c33",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45637613-c742-4a5f-99cc-e0105a811e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model\n",
    "model = Decoder(idim, odim, ts).to(device)\n",
    "ckpt = torch.load('best_model.pt', map_location='cpu')  # Load your best model\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef806ae-ac1d-4379-8c70-ab8e3c360dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()               # set model to evalutation mode\n",
    "pred, real = np.zeros((0, odim)), np.zeros((0, odim))\n",
    "for x, y in tt_load:                           # iterate through the dataloader\n",
    "    x = x.to(device)                        # move data to device (cpu/cuda)\n",
    "    with torch.no_grad():                   # disable gradient calculation\n",
    "        yh = model(x)                     # forward pass (compute output)\n",
    "        pred = np.concatenate((pred, yh.detach().cpu().numpy()))\n",
    "    real = np.concatenate((real, y.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17eebd9-d0a2-4123-905c-681c6727d793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(pred)\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(real)\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(pred - real)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f91e9-ce20-4df5-bcdb-041004742aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2 = r2_score(pred, real)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e482714b-a613-4526-8e5f-f6d45a0d2684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
